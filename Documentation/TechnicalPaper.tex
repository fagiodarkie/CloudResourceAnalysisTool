\newcommand{\filedate}{\today}
\newcommand{\fileversion}{Version 0.1}

%\documentclass{article}
\documentclass{amsart}

%%% The following command loads the amsrefs package, which will be
%%% used to create the bibliography:
%\usepackage[lite]{amsrefs}

%%% The following command defines the standard names for all of the
%%% special symbols in the AMSfonts package, listed in
%%% http://www.ctan.org/tex-archive/info/symbols/math/symbols.pdf
\usepackage{amssymb}

%%% St Mary Road symbols for theoretical computer science
\usepackage{stmaryrd}

%%% mathtools for \mathclap{} used in \sum, and \underbrace{}_n
\usepackage{mathtools}

\usepackage{url}
%\usepackage[pdfborderstyle={/S/U/W 1},hyperfootnotes=false]{hyperref}
%\usepackage[colorlinks=false,pdfborder={0 0 0}]{hyperref}
%\usepackage[colorlinks,pdfborder={0 0 0}]{hyperref}
\usepackage[colorlinks]{hyperref}
%\usepackage{hyperref}

\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}

\newcommand{\M}{\mathcal{M}}
\newcommand{\W}{\mathcal{W}}

\newcommand{\bB}[1]{\mathbb{B}_{#1}}
\newcommand{\bF}{\mathbb{F}}
\newcommand{\bS}{\mathbb{S}}
\newcommand{\itilde}{\tilde{\imath}}
\newcommand{\jtilde}{\tilde{\jmath}}
\newcommand{\ihat}{\hat{\imath}}
\newcommand{\jhat}{\hat{\jmath}}
\newcommand{\data}{\mathbb{D}}
\newcommand{\down}[1]{#1\downarrow}
\newcommand{\Int}{\N^+}
\newcommand{\Gset}{\underline{\Gamma}}
\newcommand{\eqs}{=_\Sigma}
\newcommand{\less}{<_\Sigma}
\newcommand{\leqs}{\leq_\Sigma}
\newcommand{\Const}{\texttt{Const}}
\newcommand{\wrt}{with respect to}

\renewcommand{\emptyset}{\varnothing}

% The following causes equations to be numbered within sections
\numberwithin{equation}{section}

%       Theorem environments
\theoremstyle{plain} %% This is the default, anyway
\newtheorem{thm}[equation]{Theorem}
\newtheorem{cor}[equation]{Corollary}
\newtheorem{lem}[equation]{Lemma}
\newtheorem{prop}[equation]{Proposition}

\theoremstyle{definition}
\newtheorem{defn}[equation]{Definition}

\theoremstyle{remark}
\newtheorem{rem}[equation]{Remark}
\newtheorem{ex}[equation]{Example}
\newtheorem{notation}[equation]{Notation}
\newtheorem{terminology}[equation]{Terminology}

\begin{document}

\title{Behavior types of several JVM instructions}
\author{Jacopo Freddi, Chun Tian, Michael Canella, Fabio Biselli, Giulia Baccolini}

%%% In the address, show linebreaks with double backslashes:
%\address{Dipartimento di Informatica - Scienza e Ingegneria}

%%% To have the current date inserted, use \date{\today}:
%\date{\filedate, \fileversion}


%%% To include a table of contents, uncomment the following line:
%\tableofcontents
\maketitle

\begin{abstract}
Based on the work in previous papers, we define a way to compute behavioural types for most Java bytecode instructions, in a way that they may be handled by automated verifiers to compute cost functions.\\

Theory points to fix up:
\begin{enumerate}
\item define multithread semanthics;
\item check the correctness of the rules and find out any exception that should be considered;
\item write out all the actual rules (no pseudocode) for all the instructions;
\item analize the exception solution from last year and see if it is a viable solution or if it needs to be fixed.
\end{enumerate}

\end{abstract}


\section{Conventions and mathematical constructs}


\subsection{Datatypes}
The datatypes we consider are:
\begin{itemize}
\item $\Int{} = \C{} \cup \E{} \cup \{-\}$ for integer values (augmented with an undefined value to manage expressions that the verifier cannot handle exactly);
\item $VM = \{\alpha, \beta, \gamma, \dots\} \cup \{\texttt{this}\}$ as a set of names for virtual machines;
\item $T = \{f, g, \dots\}$ as a set of thread identifiers;
\end{itemize}
$\C{}$ stands for the integer constants and is equal to $\N{}$, while $\E{}$ is the set of all expressions in which variables are involved, but can be handled by the verifier.

$\Gamma \in \Gset{}$ is a map $VM \mapsto \sigma = \{\delta, \top, \bot, a, \down{a}\}$ which holds information about the state of each virtual machine.
A general datatype $\data{} = \Int{} \cup VM \cup T$ is defined to compactly integrate all datatypes stored in the stack and the memory.

\subsection{Machine abstractions}
We consider an abstraction of the bytecode program $P$ with $n$ instructions as a function defined $\forall i \in [1 ; n]$. No checks on the domain of $P$ are made because the bytecode is only valid if all execution path end with a return statement, and in that case the analysis do not consider exceding lines of code.

The other abstractions we consider are:
\begin{itemize}
\item a memory $F \in \bF{}$ seen as a map $N \mapsto \data{}$;
\item a stack $S \in \bS{} = \emptyset \cup (\data{} \times \bS{})$;
\item a constant table $\Const{} \text{ where } \Const{}(i)$ denotes the constant $\#i$ of the bytecode unit.
\end{itemize}

To resolve the chain of constants we consider a function $c : \N{} \mapsto \texttt{String}$ that computes the closure of references and builds the identifier for invoked and referred classes and methods.

The JVM state is abstracted with a memory $F$ initially filled with the parameters of the method or program, and a stack frame $S$ initially empty. On the stack $S$ are defined the operations with the trivial semanthics, given the convention that $a\cdot b = \{a, b\} $:
\[
top(S): \bS{} \mapsto \data{}.top(S) = x \text{ if } S = x \cdot S' \in \bS{}
\]\[pop(S): \bS{} \mapsto \bS{}.pop(S) = S' \text{ if } S = x \cdot S' \in \bS{}
\]\[push(x, S): \data{} \times \bS{} \mapsto \bS{}.push(x, S) = x \cdot S
\]
being \emph{top} and \emph{pop} both intentionally partial functions, i.e. not being defined on empty stacks.\\


\section{The Greatest Lower Bound Function}

Every symbol used in the stack, memory or environment is involved in a partial ordering relationship with the other symbols of its type. The Greatest Lower Bound of two symbols, when defined, computes the greatest of the symbols lower or equal to them. The function is \emph{not} commutative: when the arguments are different but hold the same informative value, it usually gives priority to the first one. However, the ordering will only affect the value assigned to formal parameters and is not semanthic.

\subsection{$\sqcup$ on datatypes}
In general we consider a ``lowest type'' $\bot$ such that:
\[ \forall x \in \data{}: x \sqcup \bot = \bot \sqcup x = \bot \]
This type marks the ``undefined'' position and is useful to define the greatest lower bound for the memory, since the domain for it must be equal in both operands. If a greatest lower bound must be computed between $F$ and $F'$ where $\exists i. F(i) \in \data{} \wedge \nexists F'(i)$ we can say that $\exists F'(i) = \bot \wedge F(i) \sqcup F'(i) = \bot$.\\


On integers:
\[ \sqcup: \Int{} \times \Int{} \mapsto \Int{}: a \sqcup b =
\begin{cases}
- & a = - \vee b = -\\
b & a \in \C{} \wedge b \in \E{} \\
% a & a \in \E{} \wedge b \in \C{} \\
a & else
\end{cases} \]

On virtual machines:
\[ \sqcup: VM \times VM \mapsto VM: \alpha \sqcup \beta = \alpha\]

On virtual machine states:
\[ \sqcup: \sigma \times \sigma \mapsto \sigma: \alpha \sqcup \beta =
\begin{cases}
\alpha & \alpha = \beta\\
\delta & (\alpha = \top \wedge \beta = \bot) \vee (\alpha = \bot \wedge \beta = \top) \vee (\alpha = \delta \vee \beta = \delta)\\
\down{a} & (\alpha = a \wedge \beta = \bot) \vee (\alpha = \bot \wedge \beta = a) \vee (\alpha = \down{a} \vee \beta = \down{a})
\end{cases} \]

\subsection{$\sqcup$ on the memory}
\[\sqcup: \bF{} \times \bF{} \mapsto \bF{}. F_1 \sqcup F_2 = \overline{F}.\forall i \in D(\overline{F}): \overline{F}(i) = F_1(i) \sqcup F_2(i)\]

\subsection{$\sqcup$ on the stack}
\[
\sqcup: \bS{} \times \bS{} \mapsto \bS{}. S_1 \sqcup S_2 =
\begin{cases}
\emptyset & S_1 = S_2 = \emptyset\\
push(top(S_1) \sqcup top(S_2), pop(S_1) \sqcup pop(S_2)) & else
\end{cases}
\]

Notice that, being \emph{top} and \emph{pop} both partial functions, the function defined on the stack is not total: if there are some $S_1, S_2 \text{ such that } \nexists S_1 \sqcup S_2$, the stack lengths are different and the program cannot be analysed due to stack overflow errors.

\subsection{$\sqcup$ on the environment}
We define a function $D: \Gset{} \mapsto \wp(VM)$:\\
\[D(\Gamma) = d.\forall \alpha \in VM: \Gamma(\alpha) \in \sigma \implies \alpha \in d\]
that computes the domain of the environment.

\[
\sqcup: \Gset{} \times \Gset{} \mapsto \Gset{}. \Gamma_1 \sqcup \Gamma_2 = \overline{\Gamma}. D(\overline{\Gamma}) = D(\Gamma_1) \wedge \forall \alpha \in D(\overline{\Gamma}): \overline{\Gamma}(\alpha) = \Gamma_1(\alpha) \sqcup \Gamma_2(\alpha)
\]

\subsection{Definition of informative ordering}

We define a partial ordering function in $\Int{}$:
\[\less{} \subset \Int{} \times \Int{}: a \less{} b \iff
\begin{cases}
a = - \wedge b \neq -\\
a \in \E{} \wedge b \in \C{}
\end{cases}\]
\[\eqs{} \subset \Int{} \times \Int{}: \C{} \times \C{} \cup \E{} \times \E{} \cup \{(-, -)\}\]

Starting from this function, we define a partial ordering between stacks and between memories:

\[\less{} \subset \bF{} \times \bF{}: F_1 \less F_2 \iff (F_1 \leqs F_2 \wedge \exists i \in D(F_1): F_1(i) \less F_2(i))\]
\[\less \subset \bS{} \times \bS{}: S_1 \less S_2 \iff (top(S_1) \less top(S_2) \vee ((top(S_1) \eqs top(S_2) \wedge pop(S_1) \less pop(S_2))\]

The relevance of making stacks and memories comparable with respect to the information value will become clear in next section.


\section{Behavioural type function}
The behavioural type of a section of $P$ is given by the function $\bB{x}:\bF{} \times \bS{} \mapsto \bB{}$ where $\bB{i}(F, S)$ types the program from the instruction $i$ fo the end of the program considering a memory $F$ and a stack $S$. This way jumps are easily typed and branches are created in a natural way.

We consider that, $\forall i: \exists P[i] \implies \Gamma_i, F_i, S_i \vdash \bB{i}(F_i, S_i) = b_i(F_i, S_i), R_i \rhd \Gamma'$, being:
\begin{itemize}
\item $b_i$ the behavioural type from instruction $i$ to the end of the program, parametric with respect to the stack and the memory (usually written recursively);
\item $R_i$ the set of virtual machines released by the instruction (usually an empty set or a singleton);
\item $\Gamma'$ the new environment which will type the next $\bB{x}$.
\end{itemize}
Save in particular cases, the main changes happen on the stack and the memory: therefore, if not otherwise stated, we will omit $\Gamma' \text{ and } R_i$ assuming that:
\begin{itemize}
\item $R_i = \emptyset$;
\item $\Gamma' = \Gamma$.
\end{itemize}

The analysis of the program is performed in iterations of sequential scans, in which each $\bB{i}$ is computed. Ideally, when a scan discovers that $\bB{i}$ is defined on parameters $F_i, S_i$ and invoked recursively with some $F_j, S_j \text{ such that } F_j \less{} F_i \vee S_j \less{} S_i$, the domain of $\bB{i}$ is updated from $F_i, S_i \text{ to } F_i \sqcup F_j, S_i \sqcup S_j$, all the types are recomputed to mirror the update and another scan is issued to check that all invocations parameters are at least as informative as the definition. This analysis ends because:
\begin{itemize}
\item the number of instruction of a program or method is finite;
\item the chains defined by the $\less$ relationship are all finite;
\item the stack and the memory are limited by definition.
\end{itemize}

The analysis will then create, at the end of the last iteration, a set of $\bB{i}$ defined for all instructions, that will be analysed by the theorem prover and converted into cost functions.
\pagebreak
\section{Multithreading}
Multithread computation is partially handled by the theorem prover. Since the whole structure is based on recursion, the cost function for methods and threads will be recursive too. The behaviour types to express method calls are:
\begin{itemize}
\item $\nu f:\texttt{run}(t_1:par_1 \dots t_n:par_n)$, to express the call of a method or the start of a thread;
\item $f^\checkmark$, to express the synchronization of an asynchronous method or thread. Synchronous methods are synchronized right after being called.
\end{itemize}
The theorem prover will compute the right cost functions at analysis time.

We consider a simpler use case in which threads and methods cannot return virtual machines to the main thread and can only deallocate the machines that it receives as parameter. As a result, we do not need to check the synchronized sections.

The method itself is typed as $b, R$ where:
\begin{itemize}
\item $b$ is the behavioral type of the method, computed as if the method was a program. Since the method body itself starts from instruction 1 like the program, to tell apart the behavior function computing the method's behavioral type from the one computing the program's behavioral type the former one will be called $\bB{}^M$, having otherwise the same semanthics.
\item $R$ is the set of released global virtual machines. The local virtual machines are not considered of interest, as their references are forever lost once the method returns.
\end{itemize}
Both of them are parametric \wrt{} the parameters of the method \texttt{run}.

\subsubsection{Open problems}
To be able to release virtual machines, the thread must save their references somewhere before the method \texttt{run()} is called. This may be done either in its constructor or in a custom method. This behavior leads to 2 main problems:
\begin{enumerate}
\item there is no restriction on where the virtual machines are passed to the thread. Consequently, a thread must be managed in a complex way to monitor its fields;
\item there is no way to understand whether a parameter or field is a VM or an integer, due to lack of information about types in the bytecode. The only way to know that a field is a VM is to see that it is created via a creation or that a release is invoked on it.
\end{enumerate}
These problems bring to a major issue: it is extremely difficult to ensure that a virtual machine from the main thread is assigned to a field of the called thread: the process that brings to the set of released VMs is still unknown.
\subsubsection{Solution proposed by Laneve}
\begin{itemize}
\item types can be infered by the constant pool, because all methods are correctly typed and annotated\footnote{eg. \texttt{java.lang.Thread.run(\$V)\$V}};
\item the current notation about memory and stack is not complete: we need a way to express class-related fields too. We can think of it as a simple map \texttt{String} $\mapsto \data{}$ for the time being;
\item in some way, we understand that in the thread declaration each (or some) parameter is assigned to one or more specific fields of the thread: therefore, since the behavioral type and R both are parametric \wrt{} the fields, exploiting the link between field name, formal parameter and actual parameter we are able to understand which machines are released.
\item This solution works given the restriction that threads only acquire external virtual machine references in the constructor and only release them within the \texttt{run} method. Also, we need to ensure that no method aside from the constructor reassigns fields.
\end{itemize}
\subsubsection{Variations on the previous solution}
Another option is to type the thread essentially as a couple $\langle C, F \rangle$ where:
\begin{itemize}
\item C is the complete class name, in order to be able to reference its actual methods;
\item F is the field map formerly hypotesized.
\end{itemize}

Each method invoked on a thread may change its fields just like \emph{create} and \emph{release} change the machine states in the environment. It may not be necessary to type field changes for all classes, but it may be that other classes (main class included) save references of virtual machines in their fields.

In this variation, the constructor is just a method which, when typed, has the collateral effect of assigning all the thread fields. For instance, given a generic memory $F = [\texttt{this}, VM:p_1, VM:p_2, \Int:p_3]$ (we can know the types of the parameters because of the previous assumptions), the two following lines in the constructor:\\
\texttt{load\_1 \\ putfield x1}\\
have the collateral effect of updating $F$ with $[\texttt{x1} \mapsto p_1]$. In the end, the constructor type will hold the mapping between parameters \emph{p} and fields \texttt{x}, and when the constructor is invoked with actual parameters the fields will be assigned to the actual parameters instead of the formal ones. The set of released machines R should then remain parametric \wrt{} the fields, in order to keep track of possible changes until \texttt{run} is invoked. When this happens, R is instantiated with the actual field values within $\Gamma$ and the behavioral type is updated. Notice that every thread instance should keep its own set of fields and R.

\newpage
\section{Typing rules}
(T-Program)
\begin{equation*}
\frac{}
{\Gamma, F,\emptyset \vdash P: \bB{1}(F, \emptyset)}
\end{equation*}
\\
(T-Method)
\begin{equation*}
\frac{} % \bB{1}^M(F, \emptyset) =b, R^M}
{\Gamma, F,\emptyset \vdash M: \bB{1}^M(F, \emptyset)}
\end{equation*}
\\
(T-Return)
\begin{equation*}
\frac{P[i] = \text{\texttt{return}}}
{\Gamma \vdash \bB{i}(F_i, S_i) = 0}
\end{equation*}
\\
(T-If)
\begin{equation*}\frac{P[i] = \text{\texttt{if} [\emph{cond}] L}, \text{top}(S_i) \neq -}
{\Gamma \vdash \bB{i}(F_i, S_i) = [cond] (\bB{L}(F_i, \text{pop}(S_i))) +
 [\neg cond] (\bB{i+1}(F_i, \text{pop}(S_i)))}
\end{equation*}
\\
(T-If-Undefined)
\begin{equation*}\frac{P[i] = \text{\texttt{if} [\emph{cond}] L}, top(S_i) = -}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{L}(F_i, \text{pop}(S_i)) + \bB{i+1}(F_i, \text{pop}(S_i))}
\end{equation*}
\\
(T-Goto)
\begin{equation*}
\frac{P[i] = \text{\texttt{goto} $L$}}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{L}(F_i, S_i)}
\end{equation*}
\\
(T-New-VM)
\begin{equation*}\frac{
P[i] = \text{\texttt{invokevirtual createVM} }, \beta \text{ fresh}}
{\Gamma \vdash \bB{i}(F_i, S_i) = \nu \beta \fatsemi \bB{i+1}(F_i, \text{push}(\beta,\text{pop}(S_i))) \rhd \Gamma[\beta \mapsto \top]}
\end{equation*}
\\
(T-Release-VM)
\begin{equation*}
\frac{P[i] = \text{\texttt{invokevirtual releaseVM} }, \beta = \text{top}(S_i), \Gamma(\beta) \neq \bot}
{\Gamma \vdash \bB{i}(F_i, S_i) = \beta^{\checkmark} \fatsemi \bB{i+1}(F_i, \text{pop(pop}(S_i))) \rhd \Gamma[\beta \mapsto \bot], \{\beta\}}
\end{equation*}
\\
(T-Release-VM-Null)
\begin{equation*}
\frac{P[i] = \text{\texttt{invokevirtual releaseVM} }, \beta = \text{top}(S_i), \Gamma(\beta) = \bot}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, \text{pop(pop}(S_i)))}
\end{equation*}
\\
(T-Load)
\begin{equation*}
\frac{P[i] = \text{\texttt{load }} n}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, \text{push}(F(n), S_i))}
\end{equation*}
\\
(T-Store)
\begin{equation*}
\frac{P[i] = \text{\texttt{store} } n}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i[n \mapsto \text{top}(S_i)], \text{pop}(S_i))}
\end{equation*}
\\
(T-Integer-Increment-Defined)
\begin{equation*}
\frac{P[i] = \text{\texttt{iinc} } idx~n, F_i(idx) \neq -}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i[idx \mapsto (F_i(idx) + n)], S_i)}
\end{equation*}
\\
(T-Integer-Increment-Undefined)
\begin{equation*}
\frac{P[i] = \text{\texttt{iinc} } idx~n, F_i(idx) = -}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, S_i)}
\end{equation*}
\\
(T-Iconst)
\begin{equation*}
\frac{P[i] = \text{\texttt{iconst\_}}n}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, \text{push}(n, S_i))}
\end{equation*}
\\
(T-LDC)
\begin{equation*}
\frac{P[i] = \text{\texttt{ldc} } x, \Const{}(x) \in \C{}}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, \text{push}(n, S_i))}
\end{equation*}
\\
(T-LDC-Undefined)
\begin{equation*}
\frac{P[i] = \text{\texttt{ldc} } x, \Const{}(x) = -}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, \text{push}(-, S_i))}
\end{equation*}
\\
(T-Monitorenter)
\begin{equation*}
\frac{P[i] = \text{\texttt{monitorenter}}}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, S_i)}
\end{equation*}
\\
(T-Monitorexit)
\begin{equation*}
\frac{P[i] = \text{\texttt{monitorexit}}}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, S_i)}
\end{equation*}
\\
(T-Thread-New)
\begin{equation*}
\frac{\begin{aligned}
P[i] = \text{\texttt{invokespecial} } x, \Const{}(x) = \texttt{Thread.init},\\
f \text{ fresh}, \texttt{ nargs}(\texttt{Thread.init}) = n, S_{i+1} = \text{pop}^n(S_i)
\end{aligned}}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, \text{push}(f, S_{i+1})) \rhd \Gamma[f = (-, \text{run}(\text{top}^0(S_i), \dots \text{top}^{n-1}(S_i)), R)]}
\end{equation*}
\\
(T-Thread-Run)
\begin{equation*}
\frac{P[i] = \text{\texttt{invokevirtual} } x, \Const{}(x) = \texttt{Thread.run}, \text{ top}(S_i) = f \in T}
{\Gamma \vdash \bB{i}(F_i, S_i) = \nu f \fatsemi \bB{i+1}(F_i, S_i)}
\end{equation*}
\\
(T-Thread-Join)
\begin{equation*}
\frac{P[i] = \text{\texttt{invokevirtual} } x, \Const{}(x) = \texttt{Thread.join}, f = \text{top}(S_i)}
{\Gamma \vdash \bB{i}(F_i, S_i) = f^\checkmark \fatsemi \bB{i+1}(F_i, S_i)}
\end{equation*}

\texttt{More on the way...}

\end{document}
