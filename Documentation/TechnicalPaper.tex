
\newcommand{\filedate}{\today}
\newcommand{\fileversion}{Version 0.1}

%\documentclass{article}
\documentclass{amsart}

%%% The following command loads the amsrefs package, which will be
%%% used to create the bibliography:
%\usepackage[lite]{amsrefs}

%%% The following command defines the standard names for all of the
%%% special symbols in the AMSfonts package, listed in
%%% http://www.ctan.org/tex-archive/info/symbols/math/symbols.pdf
\usepackage{amssymb}

%%% St Mary Road symbols for theoretical computer science
\usepackage{stmaryrd}

%%% mathtools for \mathclap{} used in \sum, and \underbrace{}_n
\usepackage{mathtools}

\usepackage{url}
%\usepackage[pdfborderstyle={/S/U/W 1},hyperfootnotes=false]{hyperref}
%\usepackage[colorlinks=false,pdfborder={0 0 0}]{hyperref}
%\usepackage[colorlinks,pdfborder={0 0 0}]{hyperref}
\usepackage[colorlinks]{hyperref}
%\usepackage{hyperref}

\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}

\newcommand{\M}{\mathcal{M}}
\newcommand{\W}{\mathcal{W}}

\newcommand{\bB}[1]{\mathbb{B}_{#1}}
\newcommand{\bF}{\mathbb{F}}
\newcommand{\bS}{\mathbb{S}}
\newcommand{\itilde}{\tilde{\imath}}
\newcommand{\jtilde}{\tilde{\jmath}}
\newcommand{\ihat}{\hat{\imath}}
\newcommand{\jhat}{\hat{\jmath}}
\newcommand{\data}{\mathbb{D}}
\newcommand{\down}[1]{#1\downarrow}
\newcommand{\Int}{\N^+}
\newcommand{\Gset}{\underline{\Gamma}}
\newcommand{\eqs}{=_\Sigma}
\newcommand{\less}{<_\Sigma}
\newcommand{\leqs}{\leq_\Sigma}
\newcommand{\Const}{\texttt{Const}}

\renewcommand{\emptyset}{\varnothing}

% The following causes equations to be numbered within sections
\numberwithin{equation}{section}

%       Theorem environments
\theoremstyle{plain} %% This is the default, anyway
\newtheorem{thm}[equation]{Theorem}
\newtheorem{cor}[equation]{Corollary}
\newtheorem{lem}[equation]{Lemma}
\newtheorem{prop}[equation]{Proposition}

\theoremstyle{definition}
\newtheorem{defn}[equation]{Definition}

\theoremstyle{remark}
\newtheorem{rem}[equation]{Remark}
\newtheorem{ex}[equation]{Example}
\newtheorem{notation}[equation]{Notation}
\newtheorem{terminology}[equation]{Terminology}

\begin{document}

\title{Behavior types of several JVM instructions}
\author{Jacopo Freddi, Chun Tian, Michael Canella, Fabio Biselli, Giulia Baccolini}

%%% In the address, show linebreaks with double backslashes:
%\address{Dipartimento di Informatica - Scienza e Ingegneria}

%%% To have the current date inserted, use \date{\today}:
%\date{\filedate, \fileversion}


%%% To include a table of contents, uncomment the following line:
%\tableofcontents
\maketitle

\begin{abstract}
Based on the work in previous papers, we define a way to compute behavioural types for most Java bytecode instructions, in a way that they may be handled by automated verifiers to compute cost functions.

\end{abstract}


\section{Conventions and mathematical constructs}


\subsection{Datatypes}
The datatypes we consider are:
\begin{itemize}
\item $\Int{} = \C{} \cup \E{} \cup \{-\}$ for integer values (augmented with an undefined value to manage expressions that the verifier cannot handle exactly);
\item $VM = \{\alpha, \beta, \gamma, \dots\} \cup \{\texttt{this}\}$ as a set of names for virtual machines;
\item $T = \{f, g, \dots\}$ as a set of thread identifiers;
\end{itemize}
$\C{}$ stands for the integer constants and is equal to $\N{}$, while $\E{}$ is the set of all expressions in which variables are involved, but can be handled by the verifier.

$\Gamma \in \Gset{}$ is a map $VM \mapsto \sigma = \{\delta, \top, \bot, a, \down{a}\}$ which holds information about the state of each virtual machine.
A general datatype $\data{} = \Int{} \cup VM \cup T$ is defined to compactly integrate all datatypes stored in the stack and the memory.

\subsection{Machine abstractions}
We consider an abstraction of the bytecode program $P$ with $n$ instructions as a function defined $\forall i \in [1 ; n]$. No checks on the domain of $P$ are made because the bytecode is only valid if all execution path end with a return statement, and in that case the analysis do not consider exceding lines of code.

The other abstractions we consider are:
\begin{itemize}
\item a memory $F \in \bF{}$ seen as a map $N \mapsto \data{}$;
\item a stack $S \in \bS{} = \emptyset \cup (\data{} \times \bS{})$;
\item a constant table $\Const{} \text{ where } \Const{}(i)$ denotes the constant $\#i$ of the bytecode unit.
\end{itemize}

To resolve the chain of constants we consider a function $c : \N{} \mapsto \texttt{String}$ that computes the closure of references and builds the identifier for invoked and referred classes and methods.

The JVM state is abstracted with a memory $F$ initially filled with the parameters of the method or program, and a stack frame $S$ initially empty. On the stack $S$ are defined the operations with the trivial semanthics, given the convention that $a\cdot b = \{a, b\} $:
\[
top(S): \bS{} \mapsto \data{}.top(S) = x \text{ if } S = x \cdot S' \in \bS{}
\]\[pop(S): \bS{} \mapsto \bS{}.pop(S) = S' \text{ if } S = x \cdot S' \in \bS{}
\]\[push(x, S): \data{} \times \bS{} \mapsto \bS{}.push(x, S) = x \cdot S
\]
being \emph{top} and \emph{pop} both intentionally partial functions, i.e. not being defined on empty stacks.\\


\section{The Greatest Lower Bound Function}

Every symbol used in the stack, memory or environment is involved in a partial ordering relationship with the other symbols of its type. The Greatest Lower Bound of two symbols, when defined, computes the greatest of the symbols lower or equal to them. The function is \emph{not} commutative: when the arguments are different but hold the same informative value, it usually gives priority to the first one. However, the ordering will only affect the value assigned to formal parameters and is not semanthic.

\subsection{$\sqcup$ on datatypes}
In general we consider a ``lowest type'' $\bot$ such that:
\[ \forall x \in \data{}: x \sqcup \bot = \bot \sqcup x = \bot \]
This type marks the ``undefined'' position and is useful to define the greatest lower bound for the memory, since the domain for it must be equal in both operands. If a greatest lower bound must be computed between $F$ and $F'$ where $\exists i. F(i) \in \data{} \wedge \nexists F'(i)$ we can say that $\exists F'(i) = \bot \wedge F(i) \sqcup F'(i) = \bot$.\\


On integers:
\[ \sqcup: \Int{} \times \Int{} \mapsto \Int{}: a \sqcup b =
\begin{cases}
- & a = - \vee b = -\\
b & a \in \C{} \wedge b \in \E{} \\
% a & a \in \E{} \wedge b \in \C{} \\
a & else
\end{cases} \]

On virtual machines:
\[ \sqcup: VM \times VM \mapsto VM: \alpha \sqcup \beta = \alpha\]

On virtual machine states:
\[ \sqcup: \sigma \times \sigma \mapsto \sigma: \alpha \sqcup \beta =
\begin{cases}
\alpha & \alpha = \beta\\
\delta & (\alpha = \top \wedge \beta = \bot) \vee (\alpha = \bot \wedge \beta = \top) \vee (\alpha = \delta \vee \beta = \delta)\\
\down{a} & (\alpha = a \wedge \beta = \bot) \vee (\alpha = \bot \wedge \beta = a) \vee (\alpha = \down{a} \vee \beta = \down{a})
\end{cases} \]

\subsection{$\sqcup$ on the memory}
\[\sqcup: \bF{} \times \bF{} \mapsto \bF{}. F_1 \sqcup F_2 = \overline{F}.\forall i \in D(\overline{F}): \overline{F}(i) = F_1(i) \sqcup F_2(i)\]

\subsection{$\sqcup$ on the stack}
\[
\sqcup: \bS{} \times \bS{} \mapsto \bS{}. S_1 \sqcup S_2 =
\begin{cases}
\emptyset & S_1 = S_2 = \emptyset\\
push(top(S_1) \sqcup top(S_2), pop(S_1) \sqcup pop(S_2)) & else
\end{cases}
\]

Notice that, being \emph{top} and \emph{pop} both partial functions, the function defined on the stack is not total: if there are some $S_1, S_2 \text{ such that } \nexists S_1 \sqcup S_2$, the stack lengths are different and the program cannot be analysed due to stack overflow errors.

\subsection{$\sqcup$ on the environment}
We define a function $D: \Gset{} \mapsto \wp(VM)$:\\
\[D(\Gamma) = d.\forall \alpha \in VM: \Gamma(\alpha) \in \sigma \implies \alpha \in d\]
that computes the domain of the environment.

\[
\sqcup: \Gset{} \times \Gset{} \mapsto \Gset{}. \Gamma_1 \sqcup \Gamma_2 = \overline{\Gamma}. D(\overline{\Gamma}) = D(\Gamma_1) \wedge \forall \alpha \in D(\overline{\Gamma}): \overline{\Gamma}(\alpha) = \Gamma_1(\alpha) \sqcup \Gamma_2(\alpha)
\]

\subsection{Definition of informative ordering}

We define a partial ordering function in $\Int{}$:
\[\less{} \subset \Int{} \times \Int{}: a \less{} b \iff
\begin{cases}
a = - \wedge b \neq -\\
a \in \E{} \wedge b \in \C{}
\end{cases}\]
\[\eqs{} \subset \Int{} \times \Int{}: \C{} \times \C{} \cup \E{} \times \E{} \cup \{(-, -)\}\]

Starting from this function, we define a partial ordering between stacks and between memories:

\[\less{} \subset \bF{} \times \bF{}: F_1 \less F_2 \iff (F_1 \leqs F_2 \wedge \exists i \in D(F_1): F_1(i) \less F_2(i))\]
\[\less \subset \bS{} \times \bS{}: S_1 \less S_2 \iff (top(S_1) \less top(S_2) \vee ((top(S_1) \eqs top(S_2) \wedge pop(S_1) \less pop(S_2))\]

The relevance of making stacks and memories comparable with respect to the information value will become clear in next section.


\section{Behavioural type function}
The behavioural type of a section of $P$ is given by the function $\bB{x}:\bF{} \times \bS{} \mapsto \bB{}$ where $\bB{i}(F, S)$ types the program from the instruction $i$ fo the end of the program considering a memory $F$ and a stack $S$. This way jumps are easily typed and branches are created in a natural way.

We consider that, $\forall i: \exists P[i] \implies \Gamma_i, F_i, S_i \vdash \bB{i}(F_i, S_i) = b_i(F_i, S_i), R_i \rhd \Gamma'$, being:
\begin{itemize}
\item $b_i$ the behavioural type from instruction $i$ to the end of the program, parametric with respect to the stack and the memory (usually written recursively);
\item $R_i$ the set of virtual machines released by the instruction (usually an empty set or a singleton);
\item $\Gamma'$ the new environment which will type the next $\bB{x}$.
\end{itemize}
Save in particular cases, the main changes happen on the stack and the memory: therefore, if not otherwise stated, we will omit $\Gamma' \text{ and } R_i$ assuming that:
\begin{itemize}
\item $R_i = \emptyset$;
\item $\Gamma' = \Gamma$.
\end{itemize}

The analysis of the program is performed in iterations of sequential scans, in which each $\bB{i}$ is computed. Ideally, when a scan discovers that $\bB{i}$ is defined on parameters $F_i, S_i$ and invoked recursively with some $F_j, S_j \text{ such that } F_j \less{} F_i \vee S_j \less{} S_i$, the domain of $\bB{i}$ is updated from $F_i, S_i \text{ to } F_i \sqcup F_j, S_i \sqcup S_j$, all the types are recomputed to mirror the update and another scan is issued to check that all invocations parameters are at least as informative as the definition. This analysis ends because:
\begin{itemize}
\item the number of instruction of a program or method is finite;
\item the chains defined by the $\less$ relationship are all finite;
\item the stack and the memory are limited by definition.
\end{itemize}

The analysis will then create, at the end of the last iteration, a set of $\bB{i}$ defined for all instructions, that will be analysed by the theorem prover and converted into cost functions.

\section{Multithreading}
Multithread computation is partially handled by the theorem prover. Since the whole structure is based on recursion, the cost function for methods and threads will be recursive too. The behaviour types to express method calls are:
\begin{itemize}
\item $\nu f$, to express the call of a method or the start of a thread;
\item $f^\checkmark$, to express the synchronization of an asynchronous method or thread. Synchronous methods are synchronized right after being called.
\end{itemize}
The theorem prover will compute the right cost functions at analysis time.

We consider a simpler use case in which threads and methods cannot return virtual machines to the main thread and can only deallocate the machines that it receives as parameter. As a result, we do not need to check the synchronized sections.

The method itself is typed as $b, R$ where:
\begin{itemize}
\item $b$ is the behavioral type of the method, computed as if the method was a program. Since the method body itself starts from instruction 1 like the program, to tell apart the behavior function computing the method's behavioral type from the one computing the program's behavioral type the former one will be called $\bB{}^M$, having otherwise the same semanthics.
\item $R$ is the set of released global virtual machines. The local virtual machines are not considered of interest, as their references are forever lost once the method returns.
\end{itemize}

\newpage
\section{Typing rules}
(T-Program)
\begin{equation*}
\frac{}
{\Gamma, F,\emptyset \vdash P: \bB{1}(F, \emptyset)}
\end{equation*}
\\
(T-Method)
\begin{equation*}
\frac{} % \bB{1}^M(F, \emptyset) =b, R^M}
{\Gamma, F,\emptyset \vdash M: \bB{1}^M(F, \emptyset)}
\end{equation*}
\\
(T-Return)
\begin{equation*}
\frac{P[i] = \text{\texttt{return}}}
{\Gamma \vdash \bB{i}(F_i, S_i) = 0}
\end{equation*}
\\
(T-If)
\begin{equation*}\frac{P[i] = \text{\texttt{if} [\emph{cond}] L}, \text{top}(S_i) \neq -}
{\Gamma \vdash \bB{i}(F_i, S_i) = [cond] (\bB{L}(F_i, \text{pop}(S_i))) +
 [\neg cond] (\bB{i+1}(F_i, \text{pop}(S_i)))}
\end{equation*}
\\
(T-If-Undefined)
\begin{equation*}\frac{P[i] = \text{\texttt{if} [\emph{cond}] L}, top(S_i) = -}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{L}(F_i, \text{pop}(S_i)) + \bB{i+1}(F_i, \text{pop}(S_i))}
\end{equation*}
\\
(T-Goto)
\begin{equation*}
\frac{P[i] = \text{\texttt{goto} $L$}}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{L}(F_i, S_i)}
\end{equation*}
\\
(T-New-VM)
\begin{equation*}\frac{
P[i] = \text{\texttt{invokevirtual createVM} }, \beta \text{ fresh}}
{\Gamma \vdash \bB{i}(F_i, S_i) = \nu \beta \fatsemi \bB{i+1}(F_i, \text{push}(\beta,\text{pop}(S_i))) \rhd \Gamma[\beta \mapsto \top]}
\end{equation*}
\\
(T-Release-VM)
\begin{equation*}
\frac{P[i] = \text{\texttt{invokevirtual releaseVM} }, \beta = \text{top}(S_i), \Gamma(\beta) \neq \bot}
{\Gamma \vdash \bB{i}(F_i, S_i) = \beta^{\checkmark} \fatsemi \bB{i+1}(F_i, \text{pop(pop}(S_i))) \rhd \Gamma[\beta \mapsto \bot], \{\beta\}}
\end{equation*}
\\
(T-Release-VM-Null)
\begin{equation*}
\frac{P[i] = \text{\texttt{invokevirtual releaseVM} }, \beta = \text{top}(S_i), \Gamma(\beta) = \bot}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, \text{pop(pop}(S_i)))}
\end{equation*}
\\
(T-Load)
\begin{equation*}
\frac{P[i] = \text{\texttt{load }} n}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, \text{push}(F(n), S_i))}
\end{equation*}
\\
(T-Store)
\begin{equation*}
\frac{P[i] = \text{\texttt{store} } n}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i[n \mapsto \text{top}(S_i)], \text{pop}(S_i))}
\end{equation*}
\\
(T-Integer-Increment-Defined)
\begin{equation*}
\frac{P[i] = \text{\texttt{iinc} } idx~n, F_i(idx) \neq -}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i[idx \mapsto (F_i(idx) + n)], S_i)}
\end{equation*}
\\
(T-Integer-Increment-Undefined)
\begin{equation*}
\frac{P[i] = \text{\texttt{iinc} } idx~n, F_i(idx) = -}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, S_i)}
\end{equation*}
\\
(T-Iconst)
\begin{equation*}
\frac{P[i] = \text{\texttt{iconst\_}}n}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, \text{push}(n, S_i))}
\end{equation*}
\\
(T-LDC)
\begin{equation*}
\frac{P[i] = \text{\texttt{ldc} } x, \Const{}(x) \in \C{}}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, \text{push}(n, S_i))}
\end{equation*}
\\
(T-LDC-Undefined)
\begin{equation*}
\frac{P[i] = \text{\texttt{ldc} } x, \Const{}(x) = -}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, \text{push}(-, S_i))}
\end{equation*}
\\
(T-Monitorenter)
\begin{equation*}
\frac{P[i] = \text{\texttt{monitorenter}}}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, S_i)}
\end{equation*}
\\
(T-Monitorexit)
\begin{equation*}
\frac{P[i] = \text{\texttt{monitorexit}}}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, S_i)}
\end{equation*}
\\
(T-Thread-New)
\begin{equation*}
\frac{\begin{aligned}
P[i] = \text{\texttt{invokespecial} } x, \Const{}(x) = \texttt{Thread.init},\\
f \text{ fresh}, \texttt{ nargs}(\texttt{Thread.init}) = n, S_{i+1} = \text{pop}^n(S_i)
\end{aligned}}
{\Gamma \vdash \bB{i}(F_i, S_i) = \bB{i+1}(F_i, \text{push}(f, S_{i+1})) \rhd \Gamma[f = (-, \text{run}(\text{top}^0(S_i), \dots \text{top}^{n-1}(S_i)), R)]}
\end{equation*}
\\
(T-Thread-Run)
\begin{equation*}
\frac{P[i] = \text{\texttt{invokevirtual} } x, \Const{}(x) = \texttt{Thread.run}, \text{ top}(S_i) = f \in T}
{\Gamma \vdash \bB{i}(F_i, S_i) = \nu f \fatsemi \bB{i+1}(F_i, S_i)}
\end{equation*}
\\
(T-Thread-Join)
\begin{equation*}
\frac{P[i] = \text{\texttt{invokevirtual} } x, \Const{}(x) = \texttt{Thread.join}, f = \text{top}(S_i)}
{\Gamma \vdash \bB{i}(F_i, S_i) = f^\checkmark \fatsemi \bB{i+1}(F_i, S_i)}
\end{equation*}

\texttt{More on the way...}

\end{document}
